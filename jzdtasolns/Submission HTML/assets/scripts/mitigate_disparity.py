# -*- coding: utf-8 -*-
"""measure.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KhhON0RIglphVBbou-YEkSa1zZ3iiDLq
"""

#!pip install solas-ai
#!pip install notebook xgboost scikit-learn
#!pip install tabulate
#!pip install mlflow

import pandas as pd #Create dataframe
import plotly.io as pio #graphing with plotly
pio.renderers.default = "svg"
from pandas.api.types import CategoricalDtype

import solas_disparity as sd

"""In this notebook, I am measuring determining the quality of care based on a self-defined score of the facility and the patient records.

Since the data is on an individual level, the identification of the bias will Score created based on the following criteria

Process data: Multiple visits


"""

df = pd.read_csv('/content/drive/MyDrive/NIH_Project/data/diabetic_data.csv')
df.info()

df.head(5)

#Drop Weight and Payer Code
df1 = df[df.columns[~df.columns.isin(['weight','payer_code'])]]


#from pandas.api.types import CategoricalDtype
#cat_dtype = CategoricalDtype(
#    categories=[2, 1], ordered=True)
#ser.astype(cat_dtype)

#Convert to best possible dtypes
dftypes = {'encounter_id': 'char',
 'patient_nbr': 'char',
 'race': 'category',
 'age': 'int64',
 'weight': 'int64',
 'admission_type':  'category',
 'discharge_disposition_id': 'char',
  'admission_source_id': 'category',
 'time_in_hospital': 'int64',
 'payer_code': 'category',
 'medical_specialty': 'category',
 'admission_type':  'category',
}

column_names = df.columns
column_names

df.info()

#display table
#print(tabulate(data, headers=col_names))

for col in df:
  print(df[col].value_counts())

#Calculating Number of Not Caucasian patients = 25,667
19210+2037+1506+641+2273

"""In an updated version, the following values would be calculated with the information provided using a web app browswer. A report will be created with missing values so that staff can be aware of potential follow up questions. This report will also provide an overview and bring awareness to the staff of the hospital of the populations that are served with risk of inequitable healthcare experiences and access.

Total Number of Patients
Total Number of Caucasian and Not Caucasion patients
Total number of Male and Not Male patients

"""

#Total Number of patients = 101,766
76099+25667

# Calculating the percent of Caucasian = 25% and Not Caucasian = 75%
25667/101766

#Calculating percent of Male Patients= 54% and Not Male patients = 46%
101766-54708

#Not Male Patients Percentage
47058/101766

df['readmitted'].value_counts()

df['readmitted']!='NO'

#Calculate Female and Other Race = 15022 patients = 14% Risk patients
len(df[(df['gender']!='Male') & (df['race']!='Caucasian')])

39739/101766

#Calculate Seniors = 22483+17256 = 39%
22483+17256

#Calculate Number of missing payer codes
print("Number of Occurances of Missing Payer Code:"+ str(len(df[(df['payer_code']!='?')]))) #Missing Payer Code = Uninsured?
print("Number of Occurances of Checkout Time:"+ str(len(df[(df['time_in_hospital']!='?')]))) #Missing Checkout Time
print("Number of Occurances of Missing Age:"+ str(len(df[(df['age']!='?')]))) #Missing Age = Uninsured?
print("Number of Occurances of Missing Race:"+ str(len(df[(df['race']!='?')]))) #Missing Race
print("Number of Occurances of Missing Gender:"+ str(len(df[(df['gender']!='Unknown/Invalid')]))) #Missing Gender

len(df[(df['gender']!='Male') | (df['race']!='Caucasian') | (df['payer_code']=='?') | (df['payer_code']=='?') | (df['age']=='?') | (df['race']=='?') | (df['gender']=='Unknown/Invalid')])

#Prediction of Readmission based on Risk factors
import numpy as np

# Modelling
import mlflow
import mlflow.pyfunc
import mlflow.sklearn
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import roc_curve, auc, roc_auc_score
from mlflow.models.signature import infer_signature
from sklearn.preprocessing import label_binarize
from scipy import interp
from sklearn.model_selection import train_test_split


# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). 
# The following code creates a wrapper function, SklearnModelWrapper, that uses 
# the predict_proba method to return the probability that the observation belongs to each class. 
 
class SklearnModelWrapper(mlflow.pyfunc.PythonModel):
  def __init__(self, model):
    self.model = model
    
  def predict(self, context, model_input):
    return self.model.predict_proba(model_input)[:,1]
  
#Library needed to create the LabelBinarizer Function


# Tree Visualisation
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

df['readmitted'] = df['readmitted'].map({'NO':0,'>30':1,'<30':1})

df['Gender_risk'] = [1 if x !='Male' else 0 for x in df['gender']]
df['Race_risk'] = [1 if x !='?' else 0 for x in df['race']]
df['Insurance_risk'] = [1 if x !='Male' else 0 for x in df['payer_code']]
df['Attendance_risk'] = [1 if x !='Male' else 0 for x in df['time_in_hospital']]
df['Age_risk'] = [1 if x !='Male' else 0 for x in df['age']]

#specify the columns to sum
Score_calculation_columns = ['Gender_risk', 'Race_risk', 'Insurance_risk', 'Attendance_risk', 'Age_risk', ]

#define new column that contains sum of specific columns
df['Mitigation_Score'] = df[Score_calculation_columns].sum(axis=1)

"""Caucasian = 76099
Other Races = 19210+2037+1506+641+2273

Male =     54708
Female = 47055
Unknown/Invalid = 3

Weight
"""

# Split the data into features (X) and target (y)
X = df.drop('readmitted', axis=1)
y = df['readmitted']

#shuffle and split training and test sets 80:20 respectively
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

rf = RandomForestClassifier()
#rf.fit(X_train, y_train)

#https://laurenliz22.github.io/roc_curve_multiclass_predictions_random_forest_classifier
# mlflow.start_run creates a new MLflow run to track the performance of this model. 
# Within the context, you call mlflow.log_param to keep track of the parameters used, and
# mlflow.log_metric to record metrics like accuracy.

with mlflow.start_run(run_name='untuned_random_forest'):
  n_estimators = 10
  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))
  model.fit(X_train, y_train)
# predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]
  y_score = model.predict_proba(X_test)
  y_test_bin = label_binarize(y_test, classes=[0,1,2])
  n_classes = y_test_bin.shape[1]
  
  fpr = dict()
  tpr = dict()
  roc_auc = dict()
  
  for i in range(n_classes):
    fpr[i], tpr[i],_ = roc_curve(y_test_bin[:, i], y_score[:, i])
    plt.plot(fpr[i], tpr[i], color='darkred', lw=2)
    print('AUC for Class {}: {}'.format(i+1, auc(fpr[i], tpr[i])))
  mlflow.log_param('n_estimators', n_estimators)
  # Use the area under the ROC curve as a metric.
  wrappedModel = SklearnModelWrapper(model)
  # Log the model with a signature that defines the schema of the model's inputs and outputs. 
  # When the model is deployed, this signature will be used to validate inputs.
  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))
  mlflow.pyfunc.log_model("random_forest_nonoverlap_model", python_model=wrappedModel, signature=signature)