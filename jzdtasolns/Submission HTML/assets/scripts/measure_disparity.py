# -*- coding: utf-8 -*-
"""measure.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KhhON0RIglphVBbou-YEkSa1zZ3iiDLq

# Libraries, Dependencies and Packages
"""

#Modeling Dependecies
#!pip install notebook xgboost scikit-learn
#!pip install tabulate
#!pip install mlflow

#Bias Detection Dependencies
#!pip install solas-ai


#!pip install itables  #Interactive Data Table

#!pip install datable

!pip install itables  #Interactive Data Table

#Activate the interactive mode for all series and dataframes with
from itables import init_notebook_mode

init_notebook_mode(all_interactive=True)
import pandas as pd        #Create dataframe

#!pip install datable     # imported from PyPi
import pandas as pd        #Create dataframe
#import datatable as dt     #Create datatable
#import plotly.io as pio #graphing with plotly
#pio.renderers.default = "svg"
#from pandas.api.types import CategoricalDtype

#import solas_disparity as sd

#!pip --version
#pip install datatable
#import datatable as dt     #Create datatable

"""In this notebook, I am measuring determining the quality of care based on a self-defined score of the facility and the patient records.

Since the data is on an individual level, the identification of the bias will Score created based on the following criteria

Process data: Multiple visits


"""

file_location = '/content/drive/MyDrive/NIH_Project/data/diabetic_data.csv'
df = pd.read_csv(file_location)
#https://pubmed.ncbi.nlm.nih.gov/24804245/
#df.info()

from itables import show

show(df, lengthMenu=[5, 10, 25, 50, 100, 250])

"""# Data Analysis

"""

show(df.race.value_counts())

show(df.age.value_counts())

# Function to show distribution tables of values in each colum of the dataframe
#for i in df[i]
#  show(df[i].value_counts())

show(df.admission_type_id.value_counts())

admission_dict = {
    '1': '0', 
    '2': '1', 
    '3': '1',
    '4': '1',
    '5': '1',
    '6': '3',
    '7': '0', 
    '8': '0'
}

show(df.discharge_disposition_id.value_counts())

show(df.admission_source_id.value_counts())

show(df.discharge_disposition_id.value_counts())

show(df.payer_code.value_counts())

payer_dict = {
    '?': '0', 
    'MC': '1', 
    'HM)': '1',
    'SP': '1',
    'BC': '1',
    'MD': '3',
    'CP)': '0', 
    'UN': '0', 
    'CM': '0', 
    'OG': '0' 
}

show(df.time_in_hospital.value_counts())

show(df.medical_specialty.value_counts())

show(df.diabetesMed.value_counts())

show(df.admission_source_id .value_counts())

show(df.weight.value_counts())

"""# Data Preparation"""

df.dtypes

# using apply method
df[['encounter_id', 'weight','patient_nbr', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']] = df[['encounter_id', 'weight' 'patient_nbr', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']].apply(pd.to_numeric, errors='coerce')
print(df.dtypes)

column_list  = df.columns

from pandas.api.types import CategoricalDtype #Create Categorical Variables

show(df.diag_2.unique())

#Numeric Categories
encounter_id_categories = df['encounter_id'].unique().tolist()
admission_type_id_categories = df['admission_type_id'].unique().tolist()
discharge_disposition_id_categories = df['discharge_disposition_id'].unique().tolist()
admission_source_id_categories = df['admission_source_id'].unique().tolist()

#String Categories
race_categories = df['race'].unique().tolist()
gender_categories = df['gender'].unique().tolist()
age_categories = df['age'].unique().tolist()
payer_code_categories = df['payer_code'].unique().tolist()
medical_specialty_categories = df['medical_specialty'].unique().tolist()
diag_1_categories = df['diag_1'].unique().tolist()
diag_2_categories = df['diag_2'].unique().tolist()
diag_3_categories = df['diag_3'].unique().tolist()
max_glu_serum_categories = df['max_glu_serum'].unique().tolist()
A1Cresult_categories = df['A1Cresult'].unique().tolist()
metformin_categories = df['metformin'].unique().tolist()
'''
repaglinide_categories = df['repaglinide'].unique().tolist()
nateglinide_categories = df['nateglinide'].unique().tolist()
chlorpropamide_categories = df['chlorpropamide'].unique().tolist()
glimepiride_categories = df['glimepiride'].unique().tolist()
acetohexamide_categories = df['acetohexamide'].unique().tolist()
glipizide_categories = df['glipizide'].unique().tolist()
glyburide_categories = df['glyburide'].unique().tolist()
tolbutamide_categories = df['tolbutamide'].unique().tolist()
pioglitazone_categories = df['pioglitazone'].unique().tolist()
rosiglitazone_categories = df['rosiglitazone'].unique().tolist()
acarbose_categories = df['acarbose'].unique().tolist()
miglitol_categories = df['miglitol'].unique().tolist()
troglitazone_categories = df['troglitazone'].unique().tolist()
tolazamide_categories = df['tolazamide'].unique().tolist()
examide_categories = df['examide'].unique().tolist()
citoglipton_categories = df['citoglipton'].unique().tolist()
insulin_categories = df['insulin'].unique().tolist()
glyburide_metformin_categories = df['glyburide-metformin'].unique().tolist()
glipizide_metformin_categories = df['glipizide-metformin'].unique().tolist()
glimepiride_pioglitazone_categories = df['glimepiride-pioglitazone'].unique().tolist()
metformin_rosiglitazone_categories = df['metformin-rosiglitazone'].unique().tolist()
'''
change_categories = df['change'].unique().tolist()
diabetesMed_categories = df['diabetesMed'].unique().tolist()
readmitted_categories = df['readmitted'].unique().tolist()

races = CategoricalDtype(
    categories = race_categories, ordered=True)
df.race.astype(races)

encounters = CategoricalDtype(
    categories =encounter_id_categories, ordered=True)
df.encounter_id.astype(encounters)

admission_types = CategoricalDtype(
    categories =admission_type_id_categories, ordered=True)
df.admission_type_id.astype(admission_types)

discharge_ids = CategoricalDtype(
    categories = discharge_disposition_id_categories, ordered=True)
df.discharge_disposition_id.astype(discharge_ids)

genders = CategoricalDtype(
    categories = gender_categories, ordered=True)
df.gender.astype(genders)

ages = CategoricalDtype(
    categories = age_categories, ordered=True)
df.age.astype(genders)

payer_codes = CategoricalDtype(
    categories = payer_code_categories, ordered=True)
df.payer_code.astype(payer_codes)

medical_specialties = CategoricalDtype(
    categories = medical_specialty_categories, ordered=True)
df.medical_specialty.astype(medical_specialties)

diag_1s = CategoricalDtype(
    categories = diag_1_categories, ordered=True)
df.diag_1.astype(diag_1s)

diag_2s = CategoricalDtype(
    categories = diag_2_categories, ordered=True)
df.diag_2.astype(diag_2s)

diag_3s = CategoricalDtype(
    categories = diag_3_categories, ordered=True)
df.diag_3.astype(diag_3s)

max_glu_leveles = CategoricalDtype(
    categories = max_glu_serum_categories, ordered=True)
df.max_glu_serum.astype(max_glu_leveles)

A1C_levels = CategoricalDtype(
    categories = A1Cresult_categories, ordered=True)
df.A1Cresult.astype(A1C_levels)

med_levels = CategoricalDtype(
    categories = metformin_categories, ordered=True)
df.metformin.astype(med_levels)



#Drop Weight and Payer Code
#df1 = df[df.columns[~df.columns.isin(['weight','payer_code'])]]

column_names = df.columns
column_names

df.info()

#display table
#print(tabulate(data, headers=col_names))

 ffor col in df:
  print(df[col].value_counts())

#df = df.assign(categories = lambda x: (x['Total_Marks'] /500 * 100))
 
# displaying the data frame
#df

df.race.value_counts()

"""Generating Report"""

Caucasian_total = df.race.value_counts().Caucasian
print(Caucasian_total)

Male_total = df.gender.value_counts().Male
print(Male_total)

Total_Patients = len(df)

NonCaucasian_total = Total_Patients - Caucasian_total
print(NonCaucasian_total)

"""Using the facts: 
According to 
https://doi.org/10.1002/1520-7560(200005/06)16:3%3C164::AID-DMRR103%3E3.0.CO;2-R

Age, gender, body mass index, steroid and antihypertensive medication, family and smoking history contributed to the score. In the test population at 72% specificity, the sensitivity of the score was 77% and likelihood ratio 2.76. The area under the receiver-operating characteristic curve was 80%.


Equation parameters are assigned discrete values to be used in the calculation:

Female (-0.879)
Male (0)
On HTN meds (1.222)
No HTN meds (0)
On steroids (2.191)
Not on steroids (0)
BMI <25 (0)
BMI 25-27.49 (0.699)
BMI 27.5-29.99 (1.97)
BMI â‰¥30 (2.518)
No 1st degree family members with diabetes (0)
Parent OR sib with DM (0.728)
Parent AND sib with DM (0.753)
Patient is a non smoker (0)
Patient used to smoke (-0.218)
Patient is a smoker (0.855)
The formula for the score is:

Terms = 6.322 - Sex - RxHTN - RxSteroids - (0.063 * Age) - BMI - FMHxDM - SmokingHx

Risk = 100 / (1 + (e^Terms))


In this data set, age and gender are present so we will be sure to include these as impacting on score
"""

#Calculating Number of Caucasian patients
#df[race_count] = np.where(df["Active"] == "Caucasian", True, False)

#Calculating Number of Not Caucasian patients = 25,667
19210+2037+1506+641+2273

"""# Measuring Bias

In an updated version, the following values would be calculated with the information provided using a web app browswer. A report will be created with missing values so that staff can be aware of potential follow up questions. This report will also provide an overview and bring awareness to the staff of the hospital of the populations that are served with risk of inequitable healthcare experiences and access.

Total Number of Patients
Total Number of Caucasian and Not Caucasion patients
Total number of Male and Not Male patients
"""

#Total Number of patients = 101,766
76099+25667

"""# Creating A Risk Score

https://www.niddk.nih.gov/health-information/health-statistics/overweight-obesity

Using similar categories as defined here:
The following will be accounted for in the data

BMI will be estimated based on age and weight

| Syntax      | Description | Points     |
| :---        |    :----:   |          ---: |
| Header      | Missing Age       | +3   |
| Paragraph   | Missing Weight        | +3      |
| Header      | Missing Gender       | +3   |
| Paragraph   | Missing Meds        | +1      |
| Header      | Female       | +1   |
| Paragraph   | Not White        | +1      |
| Header      | BMI = (25-29.9)       | +1   |
| Header      | BMI = (30-34.9)       | +2   |
| Header      | BMI = (35-39.9)       | +3   |
| Header      | Age = (20-40)       | +1   |
| Header      | Age = (40-59)       | +2   |
| Header      | Age = (60+)       | +3   |

With these scores assigned, the Risk will be assessed as follows:

Low risk 0 < Score <= 2
At Risk  2 < Score <= 4
High Risk 4 > Score
"""

# Calculating the percent of Caucasian = 25% and Not Caucasian = 75%
25667/101766



Caucasian_Percent = 100 * Caucasian_total / Total_Patients
print(Caucasian_Percent)

#Calculating percent of Male Patients= 54% and Not Male patients = 46%
101766-54708

Male_Percent = 100 * Male_total / Total_Patients
print(Male_Percent)

#Calculate Female and Other Race = 15022 patients = 14% Risk patients
len(df[(df['gender']!='Male') & (df['race']!='Caucasian')])

NotMale_Percent = 100 * Male_total / Total_Patients
print(NotMale_Percent)

#Not Male Patients Percentage
47058/101766

df['readmitted'].value_counts()

#df['readmitted']!='NO'

#Calculate Seniors = 22483+17256 = 39%

39739/101766

#Calculate Seniors = 22483+17256 = 39%
22483+17256

#Calculate Number of missing Values
print("Number of Occurances of Missing Payer Code:"+ str(len(df[(df['payer_code']!='?')]))) #Missing Payer Code = Uninsured?
print("Number of Occurances of Checkout Time:"+ str(len(df[(df['time_in_hospital']!='?')]))) #Missing Checkout Time
print("Number of Occurances of Missing Age:"+ str(len(df[(df['age']!='?')]))) #Missing Age = Uninsured?
print("Number of Occurances of Missing Race:"+ str(len(df[(df['race']!='?')]))) #Missing Race
print("Number of Occurances of Missing Gender:"+ str(len(df[(df['gender']!='Unknown/Invalid')]))) #Missing Gender
print("Number of Occurances of Missing Weight:"+ str(len(df[(df['weight']!='?')]))) #Missing weight

len(df[(df['gender']!='Male') | (df['race']!='Caucasian') | (df['payer_code']=='?') | (df['payer_code']=='?') | (df['age']=='?') | (df['race']=='?') | (df['gender']=='Unknown/Invalid')])



#Prediction of Readmission based on Risk factors
import numpy as np

# Modelling
import mlflow
import mlflow.pyfunc
import mlflow.sklearn
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import roc_curve, auc, roc_auc_score
from mlflow.models.signature import infer_signature
from sklearn.preprocessing import label_binarize
from scipy import interp
from sklearn.model_selection import train_test_split


# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). 
# The following code creates a wrapper function, SklearnModelWrapper, that uses 
# the predict_proba method to return the probability that the observation belongs to each class. 
 
class SklearnModelWrapper(mlflow.pyfunc.PythonModel):
  def __init__(self, model):
    self.model = model
    
  def predict(self, context, model_input):
    return self.model.predict_proba(model_input)[:,1]
  
#Library needed to create the LabelBinarizer Function


# Tree Visualisation
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

df['readmitted'] = df['readmitted'].map({'NO':0,'>30':1,'<30':1})

#Assigning Scores1
#df['Gender_risk'] = [1 if x !='Male' else 0 for x in df['gender']]
#df['Race_risk'] = [1 if x !='?' else 0 for x in df['race']]
#df['Insurance_risk'] = [1 if x !='Male' else 0 for x in df['payer_code']]
#df['Attendance_risk'] = [1 if x !='Male' else 0 for x in df['time_in_hospital']]
#df['Age_risk'] = [1 if x !='Male' else 0 for x in df['age']]

#Assigning Scores1
#df['Gender_risk'] = [3 if x =='Unknown/Invalid' elif x !='Male' 1 else 0 for x in df['gender']]
#df['Gender_risk'] = [1 if x !='Male' else 0 for x in df['gender']]
#df['Gender_risk'] = [1 if x !='Male' else 0 for x in df['gender']]

#df['Race_risk'] = [3 if x =='?' else 0 for x in df['race']]
#df['Race_risk'] = [1 if x !='?' else 0 for x in df['race']]

#df['Insurance_risk'] = [3 if x =='?' else 0 for x in df['payer_code']]
#df['Insurance_risk'] = [1 if x !='Male' else 0 for x in df['payer_code']]

#df['Attendance_risk'] = [1 if x =='?' else 0 for x in df['time_in_hospital']]

#df['Weight_risk'] = [3 if x !='Male' else 0 for x in df['weight']]
#df['Weight_risk'] = [1 if x !='Male' else 0 for x in df['weight']]
#df['Weight_risk'] = [1 if x !='Male' else 0 for x in df['weight']]
#df['Weight_risk'] = [1 if x !='Male' else 0 for x in df['weight']]

#df['Age_risk'] = [3 if x !='Male' else 0 for x in df['age']]
#df['Age_risk'] = [1 if x !='Male' else 0 for x in df['age']]'''

#Calculate Number of missing Values
gender_dict = {
    'Unknown/Invalid': '3', 
    'Male': '0', 
    'Female': '1'
}
age_dict = {
    '[70-80)': '2', 
    '[60-70)': '2', 
    '[50-60)': '2',
    '[40-50)': '3',
    '[30-40)': '3',
    '[90-100)': '3'
    '[20-30)': '3', 
    '[10-20)': '1', 
    '[80-90)': '3', 
    '[0-10)': '0' 
}

weight_dict = {
    '?': '3', 
    '[75-100)': '1', 
    '[50-75)': '0',
    '[100-125)': '1',
    '[125-150)': '2',
    '[25-50)': '0',
    '[0-25)': '0', 
    '[150-175)': '2', 
    '[175-200)': '3', 
    '>200': '3'
}

race_dict = {
    'Caucasian': '0', 
    'AfricanAmerican': '1', 
    'Hispanic': '1',
    'Other': '1',
    'Asian': '1',
    '?': '3'
}


df['Gender_Risk'] = df['gender'].map(gender_dict).fillna('Other')
df['Race_risk'] = df['race'].map(race_dict).fillna('Other')
df['Insurance_risk'] = [3 if x =='?' else 0 for x in df['payer_code']]
df['Weight_Risk'] = df['weight'].map(weight_dict).fillna('Other')
df['Age_Risk'] = df['age'].map(age_dict).fillna('Other')

#specify the columns to sum
Score_calculation_columns = ['Gender_risk', 'Race_risk', 'Insurance_risk', 'Weight_risk','Age_risk']

#define new column that contains sum of specific columns
df['Mitigation_Score'] = df[Score_calculation_columns].sum(axis=1)

"""Caucasian = 76099
Other Races = 19210+2037+1506+641+2273

Male =     54708
Female = 47055
Unknown/Invalid = 3

Weight
"""

# Split the data into features (X) and target (y)
X = df.drop('readmitted', axis=1)
y = df['readmitted']

#shuffle and split training and test sets 80:20 respectively
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

rf = RandomForestClassifier()
#rf.fit(X_train, y_train)

#https://laurenliz22.github.io/roc_curve_multiclass_predictions_random_forest_classifier
# mlflow.start_run creates a new MLflow run to track the performance of this model. 
# Within the context, you call mlflow.log_param to keep track of the parameters used, and
# mlflow.log_metric to record metrics like accuracy.

with mlflow.start_run(run_name='untuned_random_forest'):
  n_estimators = 10
  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))
  model.fit(X_train, y_train)
# predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]
  y_score = model.predict_proba(X_test)
  y_test_bin = label_binarize(y_test, classes=[0,1,2])
  n_classes = y_test_bin.shape[1]
  
  fpr = dict()
  tpr = dict()
  roc_auc = dict()
  
  for i in range(n_classes):
    fpr[i], tpr[i],_ = roc_curve(y_test_bin[:, i], y_score[:, i])
    plt.plot(fpr[i], tpr[i], color='darkred', lw=2)
    print('AUC for Class {}: {}'.format(i+1, auc(fpr[i], tpr[i])))
  mlflow.log_param('n_estimators', n_estimators)
  # Use the area under the ROC curve as a metric.
  wrappedModel = SklearnModelWrapper(model)
  # Log the model with a signature that defines the schema of the model's inputs and outputs. 
  # When the model is deployed, this signature will be used to validate inputs.
  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))
  mlflow.pyfunc.log_model("random_forest_nonoverlap_model", python_model=wrappedModel, signature=signature)

pip freeze <- requirements.txt